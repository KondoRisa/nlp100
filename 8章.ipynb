{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#第8章\n",
        "第6章で取り組んだニュース記事のカテゴリ分類を題材として，ニューラルネットワークでカテゴリ分類モデルを実装する．なお，この章ではPyTorch, TensorFlow, Chainerなどの機械学習プラットフォームを活用せよ．\n",
        "\n",
        "**PyTorch** を使う"
      ],
      "metadata": {
        "id": "2IAQAjLuZck9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhJYbpXGWbso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a69eff2-49b0-4403-b05e-f87f502e5524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/nlp100/'"
      ],
      "metadata": {
        "id": "YvYJ-a-gWdfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#70. 単語ベクトルの和による特徴量\n",
        "問題50で構築した学習データ，検証データ，評価データを行列・ベクトルに変換したい．例えば，学習データについて，すべての事例xi\n",
        "の特徴ベクトルxi\n",
        "を並べた行列X\n",
        "と，正解ラベルを並べた行列（ベクトル）Y\n",
        "を作成したい．\n",
        "\n",
        "仕様に基づき，以下の行列・ベクトルを作成し，ファイルに保存せよ．\n",
        "\n",
        "* 学習データの特徴量行列: Xtrain\n",
        "* 学習データのラベルベクトル: Ytrain\n",
        "* 検証データの特徴量行列: Xvalid\n",
        "* 検証データのラベルベクトル: Yvalid\n",
        "* 評価データの特徴量行列: Xtest\n",
        "* 評価データのラベルベクトル: Ytest"
      ],
      "metadata": {
        "id": "710ufYrItCvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/nlp100/NewsAggregatorDataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXj8jNbfwyxo",
        "outputId": "60241d5a-e6c6-438d-dbed-fbf7657458d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/nlp100/NewsAggregatorDataset.zip\n",
            "replace 2pageSessions.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: 2pageSessions.csv       \n",
            "replace __MACOSX/._2pageSessions.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/._2pageSessions.csv  \n",
            "replace newsCorpora.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: newsCorpora.csv         y\n",
            "\n",
            "replace __MACOSX/._newsCorpora.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: __MACOSX/._newsCorpora.csv  \n",
            "replace readme.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
            "error:  invalid response [{ENTER}]\n",
            "replace readme.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: readme.txt              \n",
            "replace __MACOSX/._readme.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/._readme.txt   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ-9QOSL2Ndq",
        "outputId": "b5475e5e-e9d9-4ad3-8f8d-47477565e5cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "data_path = '/content/newsCorpora.csv'\n",
        "\n",
        "publisheres = [\"Reuters\", \"Huffington Post\", \"Businessweek\", \"Contactmusic.com\", \"Daily Mail\"]\n",
        "names = [\"ID\", \"TITLE\", \"URL\", \"PUBLISHER\", \"CATEGORY\", \"STORY\", \"HOSTNAME\", \"TIMESTAMP\"]\n",
        "csv_input = pd.read_csv(data_path, sep=\"\\t\", header=None, names=names)\n",
        "\n",
        "df = csv_input[csv_input[\"PUBLISHER\"].isin(publisheres)]\n",
        "\n",
        "df = df.sample(frac=1)\n",
        "\n",
        "# 訓練：検証：評価=8:1:1に分割\n",
        "x_train, x_valtest = train_test_split(df.values, test_size=0.2, random_state=0)\n",
        "x_valid, x_test = train_test_split(x_valtest, test_size=0.5, random_state=0)\n",
        "# option:strtify  ラベルの偏りをなくす\n",
        "\n",
        "# FORMAT: ID \\t TITLE \\t URL \\t PUBLISHER \\t CATEGORY \\t STORY \\t HOSTNAME \\t TIMESTAMP\n",
        "def write_file(fname, x_data):\n",
        "    with open(fname, \"w\")as fout:\n",
        "        for fact in x_data:\n",
        "            # fact[1] : 見出し\n",
        "            # fact[4] : カテゴリ\n",
        "            # b = business, t = science and technology, e = entertainment, m = health\n",
        "            if fact[4] == 'b':\n",
        "                label = '0'\n",
        "            elif fact[4] == 't':\n",
        "                label = '1'\n",
        "            elif fact[4] == 'e':\n",
        "                label = '2'\n",
        "            elif fact[4] == 'm':\n",
        "                label = '3'\n",
        "            text = \" \".join(nltk.word_tokenize(fact[1]))\n",
        "            fout.write(label + '\\t' + text + '\\n')\n",
        "            \n",
        "write_file(\"train.txt\", x_train)\n",
        "write_file(\"valid.txt\", x_valid)\n",
        "write_file(\"test.txt\", x_test)"
      ],
      "metadata": {
        "id": "H-hgneiZZjQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aecab3d6-1151-4eaf-d70a-87a8e69e2762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !gzip -d /content/drive/MyDrive/nlp100/GoogleNews-vectors-negative300.bin.gz"
      ],
      "metadata": {
        "id": "PWXdtaQ8-WBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff780acd-6bd5-404c-a961-5f5c55079333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gzip: /content/drive/MyDrive/nlp100/GoogleNews-vectors-negative300.bin.gz: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "model_path = '/content/drive/MyDrive/nlp100/GoogleNews-vectors-negative300.bin'\n",
        "w2v = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)"
      ],
      "metadata": {
        "id": "9bMHl9ANyEpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# # 学習データの特徴量行列: Xtrain\n",
        "# # 学習データのラベルベクトル: Ytrain\n",
        "# # 検証データの特徴量行列: Xvalid\n",
        "# # 検証データのラベルベクトル: Yvalid\n",
        "# # 評価データの特徴量行列: Xtest\n",
        "# # 評価データのラベルベクトル: Ytest\n",
        "\n",
        "def save_file(infname):\n",
        "    with open(infname, \"r\") as fin:\n",
        "        with open(\"X\" + infname, \"w\") as fvec, open(\"Y\" + infname, \"w\") as flabel:\n",
        "            for line in fin:\n",
        "                label, text = line.strip().split('\\t')\n",
        "                try:\n",
        "                    mean = np.mean([w2v[word] for word in text.split(' ')], axis=1)\n",
        "                    fvec.write(str(mean) + '\\n')\n",
        "                    flabel.write(label + '\\n')\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "save_file(\"train.txt\")\n",
        "save_file(\"valid.txt\")\n",
        "save_file(\"test.txt\")"
      ],
      "metadata": {
        "id": "M-Hnhgkby3kU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "# 学習データの特徴量行列: Xtrain\n",
        "# 学習データのラベルベクトル: Ytrain\n",
        "# 検証データの特徴量行列: Xvalid\n",
        "# 検証データのラベルベクトル: Yvalid\n",
        "# 評価データの特徴量行列: Xtest\n",
        "# 評価データのラベルベクトル: Ytest\n",
        "\n",
        "def create_data(infname):\n",
        "    with open(infname, \"r\") as fin:\n",
        "        vec = []\n",
        "        y_label = []\n",
        "        for line in fin:\n",
        "            label, text = line.strip().split('\\t')\n",
        "            try:\n",
        "                # mean = np.mean([w2v[word] for word in text.split(' ')], axis=1)\n",
        "                tmp_vec = [w2v[word] for word in text.split(' ')]\n",
        "                mean = sum(tmp_vec) / len(tmp_vec)\n",
        "\n",
        "                # print(mean)\n",
        "                vec.append(mean)\n",
        "                y_label.append(int(label))\n",
        "            except:\n",
        "                continue\n",
        "        return vec, y_label\n",
        "\n",
        "x_train, y_train = create_data(\"train.txt\")\n",
        "x_valid, y_valid = create_data(\"valid.txt\")\n",
        "x_test, y_test = create_data(\"test.txt\")"
      ],
      "metadata": {
        "id": "znaCWWeGL-v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otClv58oQp4w",
        "outputId": "c43f0852-1d77-4df6-8814-da792f108044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.02466901,  0.03905233, -0.03706868,  0.11861674,  0.00026449,\n",
              "        0.02161916, -0.05620956, -0.03760274,  0.12687175,  0.18186443,\n",
              "       -0.05770747, -0.02668254, -0.11054484,  0.06424967, -0.02377701,\n",
              "       -0.11365763,  0.04849752,  0.05368741, -0.04326884,  0.09051514,\n",
              "        0.0265096 ,  0.01118978,  0.09823608,  0.03806559, -0.02258809,\n",
              "        0.03462728, -0.04766146, -0.00567627, -0.03023275,  0.07553101,\n",
              "       -0.06899516, -0.07203484, -0.00072734, -0.19705708, -0.0338796 ,\n",
              "       -0.05609131,  0.02432887,  0.03576152, -0.04305013,  0.09376017,\n",
              "        0.0107015 , -0.17664592, -0.04592196, -0.08171082,  0.05003865,\n",
              "       -0.00632032, -0.11639658, -0.04033406,  0.06881714,  0.0835228 ,\n",
              "       -0.2273051 ,  0.15090434,  0.00738525,  0.00463359,  0.06213124,\n",
              "        0.03665606, -0.17370605, -0.00270844, -0.0353597 , -0.00565592,\n",
              "       -0.09235636,  0.08309937, -0.1047109 , -0.11782201, -0.10122681,\n",
              "       -0.11846288,  0.02043661,  0.06773885,  0.11298624,  0.00149536,\n",
              "       -0.06374105, -0.16735585, -0.00426483,  0.22741699, -0.03687668,\n",
              "       -0.03565979,  0.07037354, -0.03173574, -0.03811646,  0.09812164,\n",
              "        0.02663676, -0.19033813, -0.02860006,  0.05117798, -0.0466067 ,\n",
              "       -0.17049153, -0.10535685,  0.06903076,  0.13756306, -0.02714539,\n",
              "        0.04327138,  0.06413778,  0.04187648,  0.02370199,  0.02717082,\n",
              "        0.02248383,  0.05545807,  0.06195068,  0.03396289,  0.05707169,\n",
              "        0.10714722, -0.16316731,  0.0151825 , -0.06477102, -0.04926642,\n",
              "        0.06412888, -0.03155009, -0.08837891, -0.02996826, -0.00091553,\n",
              "       -0.03534953,  0.09291586,  0.07698568, -0.07171631,  0.13422649,\n",
              "        0.06386312,  0.04205322,  0.12527466,  0.03267415,  0.01505534,\n",
              "        0.06312815,  0.15308635, -0.10516357,  0.06284332,  0.07651774,\n",
              "        0.04413605, -0.04814656,  0.00498454, -0.02051798, -0.04828898,\n",
              "        0.02491252, -0.18448894,  0.03959656, -0.05996196, -0.14341228,\n",
              "       -0.03619893, -0.05223338, -0.12495422, -0.16784668,  0.12461853,\n",
              "        0.07000478, -0.11027543,  0.07261888, -0.05597432,  0.08605957,\n",
              "        0.02341715,  0.0588913 ,  0.00261434, -0.07139079, -0.0598348 ,\n",
              "        0.05445226, -0.12133535,  0.08985392, -0.03117243,  0.1108551 ,\n",
              "       -0.02516937, -0.10765585, -0.00275421,  0.03404236, -0.11415609,\n",
              "        0.02345785, -0.02949015,  0.07767487,  0.07483419,  0.00858561,\n",
              "        0.15058391,  0.01455688,  0.02714284,  0.0591685 ,  0.06173706,\n",
              "       -0.16223145,  0.03398641,  0.04884847, -0.1545461 ,  0.03733317,\n",
              "        0.05058034, -0.07728616, -0.14894104, -0.127299  , -0.12923305,\n",
              "       -0.17029826, -0.09465917, -0.00776672,  0.01496887, -0.0222702 ,\n",
              "       -0.00301743,  0.09445635,  0.01159668,  0.12000021,  0.0342865 ,\n",
              "       -0.03117371, -0.08490881, -0.01514689, -0.10451254, -0.14846802,\n",
              "        0.06026204, -0.0053304 , -0.1206843 ,  0.07402039, -0.14979045,\n",
              "       -0.05979284,  0.03156535, -0.0628713 ,  0.00056966, -0.06992086,\n",
              "        0.12423197, -0.17107773, -0.10466576, -0.08330536, -0.00556437,\n",
              "       -0.03930664,  0.01600138,  0.02698771,  0.20214844, -0.09872945,\n",
              "        0.00962321,  0.05469767,  0.02975718, -0.02104696, -0.06210836,\n",
              "       -0.09854317,  0.13837688, -0.199941  , -0.01602682, -0.03916423,\n",
              "       -0.08820216,  0.04544067,  0.00131226, -0.01071676, -0.0486908 ,\n",
              "        0.05996704,  0.03574626,  0.224528  ,  0.04607137,  0.06855774,\n",
              "       -0.11638895,  0.01365153,  0.00633494,  0.0293986 ,  0.1060791 ,\n",
              "       -0.01461538,  0.13530667,  0.09571838, -0.10437266,  0.02060954,\n",
              "       -0.01479721, -0.10306549,  0.17497762, -0.0183843 ,  0.03846232,\n",
              "       -0.06558736,  0.07973099, -0.02671051,  0.01013692,  0.00898234,\n",
              "        0.07609049, -0.04874516,  0.00197347,  0.0658671 , -0.07533296,\n",
              "        0.09466299, -0.0704244 , -0.02366129,  0.07004038,  0.05292511,\n",
              "        0.11943308, -0.15956624, -0.0027771 ,  0.06186422,  0.05689494,\n",
              "        0.12371826,  0.146993  ,  0.02469381, -0.0418396 ,  0.13747661,\n",
              "       -0.04482015, -0.11656952, -0.04316203, -0.01505534, -0.0129598 ,\n",
              "       -0.00941976,  0.11753336,  0.10394796,  0.0348409 ,  0.10428619,\n",
              "       -0.00639852, -0.09800211,  0.1155599 ,  0.08795675,  0.05182393,\n",
              "        0.07018534, -0.05340576, -0.11421856,  0.04026286, -0.04327388,\n",
              "       -0.06782023, -0.07829157,  0.03961182, -0.00386747, -0.0369161 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ファイルへの出力\n",
        "import pickle\n",
        "\n",
        "# ラベルもtensorに変換\n",
        "train_t = torch.tensor(y_train).long()\n",
        "valid_t = torch.tensor(y_valid).long()\n",
        "test_t = torch.tensor(y_test).long()\n",
        "\n",
        "with open('train.text.pickle', 'wb') as f:\n",
        "    pickle.dump(x_train, f)\n",
        "with open('train.label.pickle', 'wb') as f:\n",
        "    pickle.dump(y_train, f)\n",
        "\n",
        "with open('valid.text.pickle', 'wb') as f:\n",
        "    pickle.dump(x_valid, f)\n",
        "with open('valid.label.pickle', 'wb') as f:\n",
        "    pickle.dump(y_valid, f)\n",
        "\n",
        "with open('test.text.pickle', 'wb') as f:\n",
        "    pickle.dump(x_test, f)\n",
        "with open('test.label.pickle', 'wb') as f:\n",
        "    pickle.dump(y_test, f)\n"
      ],
      "metadata": {
        "id": "tXVNNhJIT1sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#71. 単層ニューラルネットワークによる予測\n",
        "問題70で保存した行列を読み込み，学習データについて以下の計算を実行せよ．"
      ],
      "metadata": {
        "id": "Sa8iGcuDtitW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ネットワークの定義\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.fc = nn.Linear(input_size, output_size, bias=False)\n",
        "    nn.init.normal_(self.fc.weight, 0.0, 1.0)  # 正規乱数で重みを初期化\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "# ネットワークのインスタンスを作成\n",
        "net = Net(300, 4)\n",
        "net"
      ],
      "metadata": {
        "id": "IGG5bpnpDJRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "336fe519-ded2-4c2b-926f-0f43bf1d2fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc): Linear(in_features=300, out_features=4, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.from_numpy(np.array(x_train))  \n",
        "y_train = torch.from_numpy(np.array(y_train))  "
      ],
      "metadata": {
        "id": "x6Di7332WzG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = net(x_train[0])\n",
        "x = torch.softmax(x, dim=-1)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxXc6UllVaQm",
        "outputId": "5ace0065-8cc4-40bc-e2a8-5aaa4faf4eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2545, 0.5996, 0.1091, 0.0368], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = net(x_train[:4])\n",
        "x = torch.softmax(x, dim=-1)\n",
        "x"
      ],
      "metadata": {
        "id": "16MKfN9OAw3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6076fb79-0ddd-47f1-b9d0-d313ada5422e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2545, 0.5996, 0.1091, 0.0368],\n",
              "        [0.3614, 0.0487, 0.0135, 0.5765],\n",
              "        [0.6587, 0.2773, 0.0180, 0.0461],\n",
              "        [0.3439, 0.2655, 0.1719, 0.2187]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 乱数の初期化：いろんな初期化がある．初期値で性能が変わることもある．"
      ],
      "metadata": {
        "id": "mscRXDbpDYT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#72. 損失と勾配の計算\n",
        "学習データの事例x1\n",
        "と事例集合x1,x2,x3,x4\n",
        "に対して，クロスエントロピー損失と，行列W\n",
        "に対する勾配を計算せよ．なお，ある事例xi\n",
        "に対して損失は次式で計算される．\n",
        "\n",
        "li=−log[事例xiがyiに分類される確率]\n",
        "ただし，事例集合に対するクロスエントロピー損失は，その集合に含まれる各事例の損失の平均とする．"
      ],
      "metadata": {
        "id": "TQb2cNxwtnrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# 損失の計算\n",
        "criterion = nn.CrossEntropyLoss() # クロスエントロピーの中でsoftmaxの計算を計算を行っている．softmaxをかける前に入力する．\n",
        "y = net(x_train[:1])\n",
        "t = y_train[:1]\n",
        "loss = criterion(y, t)\n",
        "\n",
        "# 勾配の計算\n",
        "net.zero_grad()\n",
        "loss.backward()\n",
        "\n",
        "print('損失 :', loss.item())\n",
        "print('勾配 :')\n",
        "print(net.fc.weight.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0CtgSuHYV-Z",
        "outputId": "d8761311-4035-49c0-ee1a-823b2d707bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "損失 : 2.8086366653442383\n",
            "勾配 :\n",
            "tensor([[-0.0059,  0.0162, -0.0017,  ..., -0.0212,  0.0188, -0.0310],\n",
            "        [-0.0030,  0.0081, -0.0008,  ..., -0.0106,  0.0094, -0.0155],\n",
            "        [ 0.0154, -0.0422,  0.0044,  ...,  0.0552, -0.0490,  0.0808],\n",
            "        [-0.0065,  0.0179, -0.0019,  ..., -0.0234,  0.0208, -0.0343]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 損失の計算\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "y = net(x_train[:4])\n",
        "t = y_train[:4]\n",
        "loss = criterion(y, t)\n",
        "\n",
        "# 勾配の計算\n",
        "net.zero_grad()\n",
        "loss.backward()\n",
        "\n",
        "print('損失 :', loss.item())\n",
        "print('勾配 :')\n",
        "print(net.fc.weight.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5I3FyUTYyhT",
        "outputId": "7d5cb397-e5a4-43dc-c49c-8efdea13bfa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "損失 : 2.076000928878784\n",
            "勾配 :\n",
            "tensor([[ 0.0028, -0.0098,  0.0440,  ...,  0.0047, -0.0193,  0.0271],\n",
            "        [-0.0005,  0.0031, -0.0018,  ..., -0.0035,  0.0037, -0.0052],\n",
            "        [ 0.0077, -0.0010, -0.0213,  ..., -0.0013,  0.0068,  0.0029],\n",
            "        [-0.0099,  0.0077, -0.0210,  ...,  0.0001,  0.0089, -0.0249]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#73. 確率的勾配降下法による学習\n",
        "確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，行列W\n",
        "を学習せよ．なお，学習は適当な基準で終了させればよい（例えば「100エポックで終了」など）．"
      ],
      "metadata": {
        "id": "JdNC4QXitsNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid = torch.from_numpy(np.array(x_valid))  \n",
        "y_valid = torch.from_numpy(np.array(y_valid)) \n",
        "x_test = torch.from_numpy(np.array(x_test))  \n",
        "y_test = torch.from_numpy(np.array(y_test))  "
      ],
      "metadata": {
        "id": "-gZYSz2CX3Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ネットワークのインスタンスを作成\n",
        "net = Net(300, 4)\n",
        "\n",
        "#損失関数の選択\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#最適化手法の選択\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
        "\n",
        "# モデルをGPUに転送\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = net.to(device)\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llERmUYWZt3a",
        "outputId": "60887e0a-52c7-4aae-a61d-0d42e466f799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DataLoaderに格納\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train = TensorDataset(x_train, y_train)\n",
        "val = TensorDataset(x_valid, y_valid)\n",
        "test = TensorDataset(x_test, y_test)\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "train_loader = DataLoader(train, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val, batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test, batch_size, shuffle=False)\n",
        "eval_loader = DataLoader(eval, batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "eufXqHBJaEBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#学習ループ \n",
        "max_epoch = 20\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "\n",
        "    # ミニバッチ学習\n",
        "    for batch in train_loader:\n",
        "\n",
        "        # バッチサイズ分のサンプルを抽出\n",
        "        x, t = batch  \n",
        "\n",
        "        # データをGPUへ転送\n",
        "        x = x.to(device)\n",
        "        t = t.to(device)\n",
        "\n",
        "        # 勾配を初期化\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 順伝播\n",
        "        y = net(x) \n",
        "        loss = criterion(y, t) \n",
        "\n",
        "        # 誤差逆伝播\n",
        "        loss.backward()  \n",
        "        optimizer.step() \n",
        "    \n",
        "    # 更新と切り離し、検証データの性能を確認\n",
        "    with torch.no_grad():\n",
        "        losses = list()\n",
        "        for batch in val_loader:\n",
        "            x, t = batch \n",
        "            x = x.to(device)\n",
        "            t = t.to(device)\n",
        "            y = net(x)  \n",
        "            loss = criterion(y, t) \n",
        "            losses.append(loss)\n",
        "    val_loss = torch.tensor(losses).mean()\n",
        "    print(\"Epoch: %02d  val_loss: %.3f\" % (epoch+1, val_loss))"
      ],
      "metadata": {
        "id": "LizvKovAtrAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6525511f-6d3b-439a-9f14-0f7bf3ac627a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01  val_loss: 0.818\n",
            "Epoch: 02  val_loss: 0.672\n",
            "Epoch: 03  val_loss: 0.636\n",
            "Epoch: 04  val_loss: 0.606\n",
            "Epoch: 05  val_loss: 0.599\n",
            "Epoch: 06  val_loss: 0.590\n",
            "Epoch: 07  val_loss: 0.589\n",
            "Epoch: 08  val_loss: 0.590\n",
            "Epoch: 09  val_loss: 0.599\n",
            "Epoch: 10  val_loss: 0.601\n",
            "Epoch: 11  val_loss: 0.596\n",
            "Epoch: 12  val_loss: 0.599\n",
            "Epoch: 13  val_loss: 0.605\n",
            "Epoch: 14  val_loss: 0.608\n",
            "Epoch: 15  val_loss: 0.617\n",
            "Epoch: 16  val_loss: 0.620\n",
            "Epoch: 17  val_loss: 0.623\n",
            "Epoch: 18  val_loss: 0.625\n",
            "Epoch: 19  val_loss: 0.632\n",
            "Epoch: 20  val_loss: 0.637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#74. 正解率の計測\n",
        "問題73で求めた行列を用いて学習データおよび評価データの事例を分類したとき，その正解率をそれぞれ求めよ．"
      ],
      "metadata": {
        "id": "7auDdGr1t0eI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    losses = list()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    for batch in val_loader:\n",
        "        x, t = batch\n",
        "\n",
        "        x = x.to(device)\n",
        "        t = t.to(device)\n",
        "        y = net(x)\n",
        "        pred = torch.argmax(y, dim=-1)\n",
        "\n",
        "        total += len(x)\n",
        "        correct += (pred == t).sum().item()\n",
        "\n",
        "print(\"valid 正解率: \", correct / total)"
      ],
      "metadata": {
        "id": "4asqmjNGtkoe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd84d4d2-9997-4664-c0fe-b1703ddef955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid 正解率:  0.8012422360248447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    losses = list()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    for batch in test_loader:\n",
        "        x, t = batch\n",
        "\n",
        "        x = x.to(device)\n",
        "        t = t.to(device)\n",
        "        y = net(x)\n",
        "        pred = torch.argmax(y, dim=-1)\n",
        "\n",
        "        total += len(x)\n",
        "        correct += (pred == t).sum().item()\n",
        "\n",
        "print(\"test 正解率: \", correct / total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIwYWenpdbO-",
        "outputId": "5810b5dd-92e4-4dbf-ac53-c5d73b2422aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test 正解率:  0.8759124087591241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#75. 損失と正解率のプロット\n",
        "問題73のコードを改変し，各エポックのパラメータ更新が完了するたびに，訓練データでの損失，正解率，検証データでの損失，正解率をグラフにプロットし，学習の進捗状況を確認できるようにせよ．"
      ],
      "metadata": {
        "id": "qz_I5-ijt38Y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AVQxcsSJt156"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#76. チェックポイント\n",
        "問題75のコードを改変し，各エポックのパラメータ更新が完了するたびに，チェックポイント（学習途中のパラメータ（重み行列など）の値や最適化アルゴリズムの内部状態）をファイルに書き出せ．"
      ],
      "metadata": {
        "id": "Mv9a11xGt65W"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dd1TIwlCt5ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#77. ミニバッチ化\n",
        "問題76のコードを改変し，B\n",
        "事例ごとに損失・勾配を計算し，行列W\n",
        "の値を更新せよ（ミニバッチ化）．B\n",
        "の値を1,2,4,8,…\n",
        "と変化させながら，1エポックの学習に要する時間を比較せよ．"
      ],
      "metadata": {
        "id": "JtR1ZTI7t-BA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bjyoACC1t8Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#78. GPU上での学習\n",
        "問題77のコードを改変し，GPU上で学習を実行せよ．"
      ],
      "metadata": {
        "id": "oMSx_-WFuBSl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mnUErfYduDGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#79. 多層ニューラルネットワーク\n",
        "問題78のコードを改変し，バイアス項の導入や多層化など，ニューラルネットワークの形状を変更しながら，高性能なカテゴリ分類器を構築せよ．"
      ],
      "metadata": {
        "id": "tx--VruTuFDN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nqKQImx0uGb0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}